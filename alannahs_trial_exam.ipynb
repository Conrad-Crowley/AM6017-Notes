{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n",
      "2.6.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "\n",
    "print(tf.__version__)\n",
    "print(tf.keras.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1 \n",
    "\n",
    "In the lecture we used a code snippet similar to the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-31 16:07:22.363611: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-03-31 16:07:22.370913: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "2022-03-31 16:07:23.482863: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "704/704 [==============================] - 49s 68ms/step - loss: 0.4089 - accuracy: 0.7986 - val_loss: 0.2893 - val_accuracy: 0.8828\n",
      "Epoch 2/2\n",
      "704/704 [==============================] - 46s 66ms/step - loss: 0.2339 - accuracy: 0.9049 - val_loss: 0.2549 - val_accuracy: 0.9000\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 400, 50)           250000    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 400, 50)           0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 398, 250)          37750     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 250)               62750     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 251       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 350,751\n",
      "Trainable params: 350,751\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "max_features = 5000\n",
    "maxlen = 400\n",
    "batch_size = 32\n",
    "embedding_dims = 50\n",
    "filters = 250\n",
    "kernel_size = 3\n",
    "hidden_dims = 250\n",
    "epochs = 2\n",
    "\n",
    "imdb = keras.datasets.imdb\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "x_train = keras.preprocessing.sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = keras.preprocessing.sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(max_features,\n",
    "                    embedding_dims,\n",
    "                    input_length=maxlen))\n",
    "model.add(keras.layers.Dropout(0.2))\n",
    "\n",
    "model.add(keras.layers.Conv1D(filters,\n",
    "                 kernel_size,\n",
    "                 padding='valid',\n",
    "                 activation='relu',\n",
    "                 strides=1))\n",
    "model.add(keras.layers.GlobalMaxPooling1D())\n",
    "model.add(keras.layers.Dense(hidden_dims))\n",
    "model.add(keras.layers.Dropout(0.2))\n",
    "model.add(keras.layers.Activation('relu'))\n",
    "model.add(keras.layers.Dense(1))\n",
    "model.add(keras.layers.Activation('sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs, \n",
    "          validation_split=0.1)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Explain this code snippet in detail. Do not use more than 800 words. (8 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```max_features = 5000``` setting the vocabulary size to be considered.\n",
    "```maxlen = 400``` the maximum length of a report\n",
    "```batch_size = 32``` the batch size\n",
    "```embedding_dims = 50``` the dimension of the embedded vectors\n",
    "```filters = 250``` the number of filters applied in the convolutiobnal layer\n",
    "```kernel_size = 3``` the kernel size in the convolutiobnal layer\n",
    "```hidden_dims = 250``` the number of nodes in the hidden dense layer\n",
    "```epochs = 2``` the number of epochs\n",
    "\n",
    "`imdb = keras.datasets.imdb` \n",
    "`(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)` \n",
    "reading in the imdb dataset & segementing the data into the predefined training and test data-sets, only including the 5000 most popular words in the dictionary. \n",
    "\n",
    "`x_train = keras.preprocessing.sequence.pad_sequences(x_train, maxlen=maxlen)`\n",
    "The preprocessing sequence pads the unknown words with 0's, and also pads reports that are too short with 0's on the end so all reports are of the same length. This padding sequence also cuts reports which are longer than maxlen to be of length maxlen. \n",
    "\n",
    "`x_test = keras.preprocessing.sequence.pad_sequences(x_test, maxlen=maxlen)`\n",
    "The same preprocessing sequence padding the test data.\n",
    "\n",
    "`model = keras.Sequential()` organises the model such that the layers are sequentially stacked. \n",
    "\n",
    "`keras.layers.Embedding(max_features,\n",
    "                    embedding_dims,\n",
    "                    input_length=maxlen)`\n",
    "The embedding layer has one-hot encoding built into it, whereby the position of each word between 0-max_features in to vocabulary is assigned a 1 in a max_features length vector, while each other position is assigned 0.\n",
    "The embedding layer then maps each of these max_features length vectors to a vector of length 'embedding_dims' by applying embedding_dims weights to each entry in the max_length vectors. The embedding layer can only be used on integer value inputs of fixed range. \n",
    " \n",
    " \n",
    " `model.add(keras.layers.Conv1D(filters,\n",
    "                 kernel_size,\n",
    "                 padding='valid',\n",
    "                 activation='relu',\n",
    "                 strides=1))` \n",
    "A 1 dimensional convolutional kernel (a 3x1 vector, where the 3 is the 'kernel_size' and the 1 is from the dimensionality of the 1-D conv layer) is applied to the outputs of the previous layer. The 'filters' weights & biases are then applied to each of the outputs of each kernel. \n",
    "`strides=1` indicates that the kernel begins on each consecutive row of the given column, rather than skipping rows.\n",
    "`padding='valid'` implies that no extra 0's are added to the sides of the inputs, (hence the output dimensioanlity is 398x250 instead of 400x250).\n",
    "`activation = relu` sets the activation function calculating the output of each node to the relu function.\n",
    "                 \n",
    "`model.add(keras.layers.GlobalMaxPooling1D())` \n",
    "Takes the maximum valued entry of each column of the input, and outputting a vector of each of these values.\n",
    "\n",
    "`model.add(keras.layers.Dense(hidden_dims))` defines a fully-connected layer consisting of 250 nodes. Each of the ouputs from the previous layer is connected to all of the nodes in the dense layer, by a certain weight to which a bias is the applied.\n",
    "\n",
    "`model.add(keras.layers.Dropout(0.2))`\n",
    "The dropout layer removes nodes from the dense layer at random during training. The proportion of nodes removed is defined in the function - in this case 0.2 of the 250 nodes are removed.\n",
    "\n",
    "`model.add(keras.layers.Activation('relu'))` is an activation layer applied to the dense layers nodes using the ReLU activation function.  The reLU activation function reuturns 0 for input values x <= 0, and x for x>0.\n",
    "\n",
    "    $$ f(x) = \\begin{cases} -0 & x\\leq 0 \\\\-x  & x>0 \\end{cases} $$\n",
    "\n",
    "`keras.layers.Dense(1)` defines a fully-connected layer of one node, where each neuron input will be connected to every output of the previous layer, with weights and biases applied. \n",
    "\n",
    "`model.add(keras.layers.Activation('sigmoid'))` is an activation layer applied to the dense layer using the sigmoid function as an activation fuction. The sigmoid function returns values between 0 and 1, and can be used to convert the inputs of the layer to a probability ditribution. The sigmoid function is used as the final activation function in binaray classification problems.\n",
    "\n",
    "`model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])`\n",
    "Complies the model with the binary crossentrophy function as the loss function, and the *Adam* optimisation function. The accuracy is also printed so we know to what extent the model is predicting correctly.              \n",
    "              \n",
    "`model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs, \n",
    "          validation_split=0.1)`\n",
    "Trains the model on the training data, using a batch size (the number of articles considered in one training step) of batch_size, and the number of epochs (the number of times the entire training data is passed through the model) = epochs. The validation split =0.1 means that 0.1 of the training data is not used to train the model, but rather to validate how well the model is performaing on unseen articles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a461500edaac651e784e739fd5b76f2f",
     "grade": true,
     "grade_id": "cell-8dfecdeefb27817c",
     "locked": false,
     "points": 8,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) The line `model.summary()` displays the number of trainable parameters in each layer. Precisely explain those numbers for each layer. Do not use more than 300 words. (3 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f30885e824008a84d79757de545436a7",
     "grade": true,
     "grade_id": "cell-a08b398463318a42",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 400, 50)           250000    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 400, 50)           0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 398, 250)          37750     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 250)               62750     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 251       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 350,751\n",
      "Trainable params: 350,751\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Embedding: has 5000x50 weights to train\n",
    "    Dropout, max_pooling and activation layers have no parameters to train.\n",
    "    conv1D has 3 (kernel)x 50 (input) x 250 weights+ 250 biases to train.\n",
    "    dense(250) has 250x250 weights + 250 biases to train.\n",
    "    dense(1) has 1x250 weights + 1 bias to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37750"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3*50*250 +250"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Rewrite the above snippet using the Keras functional API. (3 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4eb848bd47e5d56094ace0976276c97d",
     "grade": true,
     "grade_id": "cell-ca3cdc119cec9e39",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_31063/720374450.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"api_imdb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m#keras.utils.plot_model(model, show_shapes=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "inputs = keras.Input(shape=(400), name=\"img\")\n",
    "x = keras.layers.Embedding(max_features,\n",
    "                    embedding_dims,\n",
    "                    input_length=maxlen)(inputs)\n",
    "x = keras.layers.Dropout(0.2)(x)\n",
    "x = keras.layers.Conv1D(filters, 3, activation=\"relu\")(x)\n",
    "block_1_output = keras.layers.GlobalMaxPooling1D()(x)\n",
    "\n",
    "x = keras.layers.Dense(hidden_dims, activation = \"relu\")(block_1_output)\n",
    "x = keras.layers.Dropout(0.2)(x)\n",
    "\n",
    "outputs = keras.layers.Dense(1, activation =\"sigmoid\")(x)\n",
    "\n",
    "model = keras.Model(inputs, outputs, name=\"api_imdb\")\n",
    "#keras.utils.plot_model(model, show_shapes=True)\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "704/704 [==============================] - 46s 65ms/step - loss: 0.4131 - accuracy: 0.7918 - val_loss: 0.2740 - val_accuracy: 0.8844\n",
      "Epoch 2/2\n",
      "704/704 [==============================] - 45s 65ms/step - loss: 0.2328 - accuracy: 0.9052 - val_loss: 0.2553 - val_accuracy: 0.8972\n",
      "Model: \"api_imdb\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "img (InputLayer)             [(None, 400)]             0         \n",
      "_________________________________________________________________\n",
      "embedding_4 (Embedding)      (None, 400, 50)           250000    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 400, 50)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 398, 250)          37750     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_2 (Glob (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 250)               62750     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 251       \n",
      "=================================================================\n",
      "Total params: 350,751\n",
      "Trainable params: 350,751\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs, \n",
    "          validation_split=0.1)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is a functional API? Recall we used a different API to write the software where two layers co-existed, rather than one layer after the other. Functional ApI is lecture L07. The course is designed in a way that if you follow the links a little bit deeper now you should get a better understanding now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2 Overfitting\n",
    "\n",
    "a) Explain the problem of *overfitting* in the context of Machine Learning. Do not use more than 400 words. (4 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "567150b22f12d4a2ee974dabec1a2111",
     "grade": true,
     "grade_id": "cell-91c2f314806134db",
     "locked": false,
     "points": 4,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "Over-fitting occurs when a model can predict the patterns in the training data-set with a higher\n",
    "accuracy compared with the test and validation data-sets. \n",
    "\n",
    "For example if a tudent practiced solving one type of question over and over again in preparation for an exam, and became excellent at doing that question. The question on a exam was a different question, and the student performed only medicorately on the exam. The student couldn't adapt to the differences in the question.\n",
    "\n",
    "Similarly an overfitted model performs extremely well on the data on which it is trained, however its accuracy is lower on unseen data, and its loss is higher on the unseen data than the trained data aswell. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Explain three different methods, which are used to address the problem of overfitting. Do not use more than 600 words. (6 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fb0b31f9561c5118f99a1564c4e21126",
     "grade": true,
     "grade_id": "cell-640d32c18e6f3e99",
     "locked": false,
     "points": 6,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "### Dropout layers\n",
    "Drop-out layers remove a specified percentage/number of nodes at random in a layer within a model during training. For example 20% of the nodes could be removed from a layer (activation is not applied to the neurons, and they are discounted rom weight distribution). They\n",
    "reduce over-fitting as they stop the model from becoming overly reliant on the training data-set. \n",
    "### Data Augmentation\n",
    "Training a model on too little data can cause model overfitting. Data augmentation is a method which can be used to supplement data-sets which aren’t large enough to train a model effectively by augmenting the available data, in a way that's appropriate to the dataset. For example, data aug-\n",
    "mentation of a data-set of images involves the rotation of the available images within a fixed range (e.g. 5 degrees about\n",
    "the vertical axis), as well as flipping the image about the vertical and horizontal axis.\n",
    "### Early stopping\n",
    "Early stopping can be applied to a model to stop it from continuing to train when the validation accuracy starts decreasing (or when the validation loss starts increasing). After a certain number of iterations (epochs) the model perforamance stops improving, and then begins decreasing again. Early stopping can be applied either as a function, or by hand by examining the plots of the validation accuracy and loss over a large number of epochs, and selecting the epochs on which to optimise the model by eye. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Provide a working code example, which illustrates the effectiveness of one of the methods discussed in the previous subquestion. (4 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e1b33499b8a7ee58b7fc2597eb0d5ca8",
     "grade": true,
     "grade_id": "cell-de175880aca196f0",
     "locked": false,
     "points": 4,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "704/704 [==============================] - 47s 66ms/step - loss: 0.3884 - accuracy: 0.8096 - val_loss: 0.2891 - val_accuracy: 0.8816\n",
      "Epoch 2/2\n",
      "704/704 [==============================] - 47s 67ms/step - loss: 0.1993 - accuracy: 0.9223 - val_loss: 0.3170 - val_accuracy: 0.8712\n",
      "Model: \"api_imdb\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "img (InputLayer)             [(None, 400)]             0         \n",
      "_________________________________________________________________\n",
      "embedding_5 (Embedding)      (None, 400, 50)           250000    \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 398, 250)          37750     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_3 (Glob (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 250)               62750     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 251       \n",
      "=================================================================\n",
      "Total params: 350,751\n",
      "Trainable params: 350,751\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "inputs = keras.Input(shape=(400), name=\"img\")\n",
    "x = keras.layers.Embedding(max_features,\n",
    "                    embedding_dims,\n",
    "                    input_length=maxlen)(inputs)\n",
    "#x = keras.layers.Dropout(0.2)(x)\n",
    "x = keras.layers.Conv1D(filters, 3, activation=\"relu\")(x)\n",
    "block_1_output = keras.layers.GlobalMaxPooling1D()(x)\n",
    "\n",
    "x = keras.layers.Dense(hidden_dims, activation = \"relu\")(block_1_output)\n",
    "#x = keras.layers.Dropout(0.2)(x)\n",
    "\n",
    "outputs = keras.layers.Dense(1, activation =\"sigmoid\")(x)\n",
    "\n",
    "model2 = keras.Model(inputs, outputs, name=\"api_imdb\")\n",
    "\n",
    "model2.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model2.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs, \n",
    "          validation_split=0.1)\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can insert snippets from throughout the course or of similar standard which demonstrates that one of the methods mentioned in b is effective. It should be a simple example, you shouldn't be waiting 10 mins for the model to train."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3 \n",
    "\n",
    "a) Explain the following related concepts and the connections between them:\n",
    "  - One-hot encoding\n",
    "  - softmax layer\n",
    "  - sparse categorical crossentropy\n",
    "\n",
    "Do not use more than 800 words. \n",
    "(8 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot encoding\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "59830d0bb3d0028e96387b89267f182f",
     "grade": true,
     "grade_id": "cell-24b1975d527c284b",
     "locked": false,
     "points": 8,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "One-hot encoding: number converted to vector, where the vector consists of one 1 and the rest are 0s.\n",
    "\n",
    "Softmax layer: At the end we want to have a layer so that the output layer can be intertppeted as a probability distribution.\n",
    "\n",
    "Sparse categorical crossentrophy: If we want to later on have a function, and softmax layer to categorise the data at the end, we want to tell the system how wrong it is if it comes up with the wrong probability distribution at the end. Punishes system for getting wrong distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Using only elementary Python or the Numpy library, define a function `softmax(myarray)` which calculates the softmax function for a batch of samples. Here `myarray` is a rank 2 numpy array, where `myarray.shape[0]` is the number of samples and `myarray.shape[1]` is the number of categories. The function is supposed to return an array `mysoftmax`, which has the same shape as `myarray`. (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6393d09dc16ff9646a97aa64fd9162d1",
     "grade": true,
     "grade_id": "cell-29e3b3f2a179bbb6",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def softmax(myarray):\n",
    "    mysoftmax = np.zeros(np.shape(myarray))\n",
    "    for i in range(myarray.shape[0]):\n",
    "        total = np.sum(np.exp(myarray[i,:]))\n",
    "        for j in range(myarray.shape[1]):\n",
    "            mysoftmax[i,j] = np.exp(myarray[i,j])/total\n",
    "    \n",
    "    return mysoftmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Using only elementary Python or the Numpy library, define a function `sparse_categorical_crossentropy(mysoftmax, mylabels)` which calculates the sparse categorical crossentropy error function for a batch of samples. Here `mysoftmax` is an array of the same shape as `myarray` in the previous subquestion. `mylabels` is a numpy array of `mysoftmax.shape[0]` integers between 0 and `mysoftmax.shape[1]-1`. The function is supposed to return a single number. (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "83be31d51644fd677d6db58339f5c0a2",
     "grade": true,
     "grade_id": "cell-d79fa1b35f494cf3",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def sparse_categorical_crossentropy(mysoftmax, mylabels):\n",
    "    onehotlabels = np.zeros(np.shape(mysoftmax))\n",
    "    loss = np.zeros(len(mylabels))\n",
    "    for i in range(len(mylabels)):\n",
    "        onehotlabels[i,mylabels] = 1\n",
    "    for j in range(len(mylabels)):\n",
    "        loss[j] = -(1/len(mylabels)) *np.sum(onehotlabels[j,:]*np.log(mysoftmax[j,:])+(1-onehotlabels[j,:])*np.log(1-mysoftmax[j,:]))\n",
    "    return np.sum(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function for sparse categorical crossentrophy using elementary pyhton and numpy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Using only elementary Python or the Numpy library, define a function `accuracy(mysoftmax, mylabels)` which calculates the accuracy of the predictions in `mysoftmax` when compared to the actual labels in `mylabels`. The shape of these two arrays are as in the previous subquestion. The function is supposed to return a single number. (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "57d37054db020d3630f6475c84e776b0",
     "grade": true,
     "grade_id": "cell-8f3bc34d763e2c4a",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def accuracy(mysoftmax, mylabels):\n",
    "    counter = 0\n",
    "    for i in range(len(mylabels)):\n",
    "        if np.argmax(mysoftmax[i,:]) == mylabels[i]:\n",
    "            counter= counter+1\n",
    "    acc = counter / len(mylabels)    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[1,2,3,4],[4,6,8,10]])\n",
    "alab = np.array([3,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(softmax(a),alab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax(a)\n",
    "np.argmax(softmax(a)[0,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q4 Backpropagation\n",
    "\n",
    "a) Explain the concept of *backpropagation* in the context of *Artificial Neural Networks* in your own words.  Address the following points in your answer:\n",
    "- What is the background of the problem to be addressed?\n",
    "- What problem is addressed?\n",
    "- How does it work?\n",
    "- What are the numerical challenges and how can they be addressed?\n",
    "- What factors influence the performance?\n",
    "\n",
    "Provide links to all sources used in your answer. Do not use more than 700 words. (7 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3109dc3f9b321c8847aaab75b410c2a3",
     "grade": true,
     "grade_id": "cell-9d7bccf7667990ac",
     "locked": false,
     "points": 7,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Explain the concept of *backpropagation through time* in the context of *Recurrent Neural Networks*.   Address the following points in your answer:\n",
    "- What is the background of the problem to be addressed?\n",
    "- What problem is addressed?\n",
    "- How does it work?\n",
    "- What are the numerical challenges and how can they be addressed?\n",
    "- What factors influence the performance?\n",
    "\n",
    "Provide links to all sources used in your answer. Do not use more than 700 words. (7 points) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "de62004b348c45922891daf4c9f2c5d2",
     "grade": true,
     "grade_id": "cell-e06feccf44cc1c3c",
     "locked": false,
     "points": 7,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Topics have changed a bit throughout the years but it should mostly be familiar to us. 30mins per question."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf]",
   "language": "python",
   "name": "conda-env-tf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
